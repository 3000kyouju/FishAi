{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe9vkEvFABbN"
   },
   "source": [
    "[![Roboflow Notebooks](https://ik.imagekit.io/roboflow/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
    "\n",
    "# How to Train YOLOv8 Instance Segmentation on a Custom Dataset\n",
    "\n",
    "---\n",
    "\n",
    "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset)\n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wuZtUMEiKWY)\n",
    "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
    "\n",
    "Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
    "\n",
    "## âš ï¸ Disclaimer\n",
    "\n",
    "YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **03.01.2024** with version **YOLOv8.0.196**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "## Accompanying Blog Post\n",
    "\n",
    "We recommend that you follow along in this notebook while reading the blog post on how to train YOLOv8 Instance Segmentation, concurrently.\n",
    "\n",
    "## Pro Tip: Use GPU Acceleration\n",
    "\n",
    "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
    "\n",
    "## Steps in this Tutorial\n",
    "\n",
    "In this tutorial, we are going to cover:\n",
    "\n",
    "- Before you start\n",
    "- Install YOLOv8\n",
    "- CLI Basics\n",
    "- Inference with Pre-trained COCO Model\n",
    "- Roboflow Universe\n",
    "- Preparing a custom dataset\n",
    "- Custom Training\n",
    "- Validate Custom Model\n",
    "- Inference with Custom Model\n",
    "- Deploy the Trained Model to Roboflow\n",
    "\n",
    "**Let's begin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRdDYkqAKN4"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "ad36371d-5234-41b5-ed1b-facf55b69721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 27 16:03:49 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4500               Off |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   36C    P8             27W /  200W |    2685MiB /  20470MiB |     12%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1886      G   /usr/lib/xorg/Xorg                            209MiB |\n",
      "|    0   N/A  N/A      2077      G   /usr/bin/gnome-shell                          168MiB |\n",
      "|    0   N/A  N/A     50465      G   ...seed-version=20240826-180135.073000         64MiB |\n",
      "|    0   N/A  N/A     50630      C   ...ra/anaconda3/envs/yolov8/bin/python        760MiB |\n",
      "|    0   N/A  N/A     52700      G   /snap/vlc/3777/usr/bin/vlc                     32MiB |\n",
      "|    0   N/A  N/A     54061      G   ...irefox/4793/usr/lib/firefox/firefox       1388MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "e3030c34-c1f8-4e69-879b-ef7748450f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nakahira/workspace/Nishida/fish/seavis1003\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "âš ï¸ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **03.01.2024** with version **YOLOv8.0.196**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two waysâ€Š-â€Šfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "b1d8ac7a-d223-48de-c479-3f7a93ff4b35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA RTX A4500, 20047MiB)\n",
      "Setup complete âœ… (20 CPUs, 62.6 GB RAM, 205.9/915.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.196\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VOEYrlBoP9-E"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '{HOME}'\n",
      "/home/nakahira/workspace/Nishida/fish/seavis1003\n",
      "/home/nakahira/anaconda3/lib/python3.12/site-packages/ultralytics/nn/tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.4 torch-2.4.0+cu121 CUDA:0 (NVIDIA RTX A4500, 20047MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
      "image 1/1 /home/nakahira/workspace/Nishida/fish/seavis1003/dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 1 handbag, 37.9ms\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 72.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!yolo task=segment mode=predict model=yolov8s-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K33S7zlkQku0",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
    "\n",
    "```\n",
    "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
    "          classify       predict        yolov8n-cls.yaml  args...\n",
    "          segment        val            yolov8n-seg.yaml  args...\n",
    "                         export         yolov8n.pt        format=onnx  args...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1qD4toTTw0"
   },
   "source": [
    "### ðŸ’» CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaE1kLS8R4CV"
   },
   "source": [
    "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (1.1.33)\n",
      "Requirement already satisfied: certifi in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (2024.6.2)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: idna==3.7 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from matplotlib->roboflow) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from matplotlib->roboflow) (4.53.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from matplotlib->roboflow) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nakahira/anaconda3/envs/yolov8/lib/python3.12/site-packages (from requests->roboflow) (3.3.2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"jSLqWbf9yKIHEIR7GrtN\")\n",
    "project = rf.workspace(\"kota-h6pkq\").project(\"fish-pgpgz\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nakahira/workspace/Nishida/fish/seavis1003/fish-1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "b9c28885-60eb-4fe4-f94e-63ec59ad2be1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "New https://pypi.org/project/ultralytics/8.3.3 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.4 torch-2.4.0+cu121 CUDA:0 (NVIDIA RTX A4500, 20047MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=/home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/data.yaml, epochs=300, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2771318  ultralytics.nn.modules.head.Segment          [2, 32, 128, [128, 256, 512]] \n",
      "YOLOv8s-seg summary: 261 layers, 11790870 parameters, 11790854 gradients, 42.7 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/train/la\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/valid/labe\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/valid/labels.cache\n",
      "Plotting labels to runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300      1.44G      1.684       2.52      5.319      1.097          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.371      0.311      0.283      0.171      0.349      0.345      0.255      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300      1.47G      1.582      2.137      3.604      1.016          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.519      0.552      0.502      0.281      0.479      0.507      0.445      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300      1.49G      1.514      2.107      3.404     0.9522          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157     0.0748      0.267     0.0525     0.0274     0.0718      0.257     0.0476     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300      1.49G      1.643      2.465       3.19      1.053          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.194      0.103      0.138     0.0897      0.124      0.246      0.143     0.0716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300      1.49G      1.738      2.302      4.186      1.076          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.344      0.345      0.358      0.208      0.409      0.329      0.377       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300      1.49G      1.822      2.547      4.255      1.186         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.352      0.288      0.305      0.145      0.355      0.297       0.32      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300      1.49G      1.828      2.803        2.5      1.128          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.363      0.353      0.352      0.151      0.241      0.237      0.162      0.035\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300       1.5G      1.668        2.3      2.272      1.074         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.447      0.396      0.403      0.191      0.407      0.357      0.329      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300       1.5G      1.931      2.437      2.248      1.145          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.419      0.504      0.412      0.215      0.395      0.475      0.381      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/300      1.48G       1.78      2.673      2.092      1.176          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.429      0.524      0.423      0.226      0.412      0.493      0.381      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/300      1.49G      1.736      2.088      2.113      1.119          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.435      0.558      0.511      0.261      0.557      0.399        0.5      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/300       1.5G      1.799      2.066      1.828       1.14         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.448      0.609       0.48      0.235      0.419        0.6      0.422      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/300      1.49G      1.706      2.134       2.22      1.142          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.872      0.366      0.393      0.206       0.84      0.303      0.319     0.0924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/300      1.49G      1.697      1.783      1.747      1.157          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.495      0.504      0.495      0.263       0.48      0.483      0.467      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/300      1.49G       1.62      1.721       1.62      1.073          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.315      0.592      0.362      0.188      0.326      0.554      0.373      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/300      1.49G      1.628      1.617      1.635      1.073          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.465      0.612      0.597      0.288      0.456      0.599      0.577      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/300      1.49G      1.567      1.669      1.694      1.104          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.877      0.435      0.495      0.282       0.85      0.405      0.453      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/300      1.49G      1.658      2.115      1.807      1.099          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.407      0.444      0.459      0.253      0.387      0.422      0.432      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/300      1.49G       1.85      2.531      1.829      1.141         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.51      0.647       0.57      0.321      0.496      0.638      0.562      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/300      1.49G      1.607      1.637      1.487      1.082          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.524      0.595       0.59      0.322       0.52      0.591      0.576      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/300      1.47G      1.564      2.078      2.256      1.023          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.487      0.637      0.633      0.317      0.467      0.607      0.574      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/300       1.5G      1.653      2.138      1.611      1.089          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.922      0.427       0.61      0.347      0.906      0.409      0.577      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/300      1.49G      1.522       1.79      1.645      1.127          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.914      0.434      0.576      0.328      0.906      0.426      0.563      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/300      1.49G      1.629      1.874      1.549      1.064          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.907      0.409      0.593      0.331      0.903      0.405      0.585      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/300      1.47G      1.568       1.63      1.422      1.053          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.475      0.625      0.609      0.359      0.452      0.612      0.591       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/300      1.49G      1.573      1.926      1.459      1.092          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.586      0.653       0.62      0.349       0.57      0.627      0.595       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/300      1.49G      1.633      1.962      1.364      1.095          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.52      0.686      0.647      0.369      0.515      0.677      0.632      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/300      1.49G      1.653      1.791      1.412      1.035          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.623      0.696      0.649      0.392      0.616      0.682      0.632      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/300      1.49G      1.498      1.778      1.239      1.034          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.714      0.641      0.658        0.4      0.705      0.634      0.644      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/300      1.49G      1.534      1.817      1.395     0.9995         14   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.675      0.661      0.656      0.392      0.643      0.635       0.62      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/300      1.47G      1.627       1.55      1.186      1.103          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.725      0.601      0.631      0.362      0.712      0.588      0.602      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/300      1.49G      1.382       1.36      1.181      1.036          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.642      0.704      0.654        0.4      0.625      0.683       0.62      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/300      1.49G      1.475      1.387      1.179      1.029         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.771      0.697      0.757      0.455      0.759      0.684      0.734      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/300      1.49G      1.465      1.516      1.235      1.049          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.701      0.744      0.794       0.48      0.689      0.735      0.772      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/300      1.49G      1.651      1.526      1.724      1.083          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.682      0.761      0.734      0.422      0.662      0.696      0.695      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/300      1.49G      1.453       1.39       1.25      1.057          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.621      0.616      0.681      0.413      0.603      0.595      0.651      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/300      1.49G      1.541      1.591      1.464      1.074          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.645      0.611      0.695      0.416      0.632      0.587      0.662      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/300      1.49G      1.459      1.385      1.276      1.028          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.661      0.694      0.743      0.451      0.626      0.706      0.729      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/300      1.49G      1.406      1.433      1.157      1.041          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.757      0.751      0.809      0.512      0.747       0.74      0.793      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/300      1.49G      1.387       1.69      1.217      1.025          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.791      0.758      0.823        0.5      0.773       0.74      0.801      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      1.49G      1.399      1.581      1.126      1.042         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.833      0.772       0.81      0.504      0.785      0.729      0.763      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      1.48G      1.336      1.428      1.124     0.9741          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.822      0.781      0.815      0.506       0.79      0.751      0.773      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      1.51G      1.398        1.7      1.295      1.015          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.632      0.711      0.784      0.477      0.594      0.676       0.75      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      1.49G      1.428      1.874      1.298      1.044          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.698      0.724       0.79      0.489      0.682      0.695      0.762      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      1.49G      1.389      1.389      1.208     0.9981         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.874      0.685      0.777      0.484      0.844      0.671      0.745      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      1.48G      1.415      1.528      1.266      1.019          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.74      0.719      0.768      0.495      0.717      0.677      0.729      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      1.49G      1.405      1.438      1.172      1.013          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.767      0.628      0.726      0.446      0.743      0.611        0.7      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      1.49G      1.343      1.395       1.04     0.9646          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.819      0.599      0.703      0.427      0.816      0.595      0.692       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      1.48G      1.327       1.36      1.339     0.9054          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.743      0.664      0.723      0.437      0.701      0.624      0.684      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      1.49G      1.484      1.538      1.601          1          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.733      0.634      0.709      0.387      0.688      0.578      0.656      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      1.49G      1.544      1.704      1.865      1.032          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.676      0.636      0.715      0.423      0.625       0.58      0.655      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      1.48G       1.48      1.606      1.495      1.005          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.622      0.652      0.709      0.449      0.613      0.643      0.702      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      1.48G      1.377      1.439      1.344     0.9658          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.727       0.62      0.732      0.469      0.728       0.62      0.731      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      1.49G      1.312      1.439       1.22     0.9892          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.702      0.739      0.765      0.485      0.687      0.717      0.745      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      1.48G      1.291      1.336      1.366      1.065          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.732      0.778      0.809       0.51      0.721      0.746       0.78      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      1.49G      1.346      1.421      1.294       1.01          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.786      0.795      0.831      0.526      0.739      0.764      0.786      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      1.49G      1.336      1.544      1.209      1.054          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.733      0.745      0.759      0.497      0.718      0.728      0.731      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300      1.48G      1.251      1.584      1.241     0.9986          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.738      0.672      0.719      0.478      0.729      0.663      0.702      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      1.48G      1.283      1.434      1.476     0.9708          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.754      0.672      0.737      0.483      0.754      0.672      0.728       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      1.49G      1.437      1.728      1.301      1.028          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.681      0.744      0.777      0.511      0.672      0.728      0.755      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      1.47G      1.319      1.426      1.314     0.9564          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.716      0.791      0.786      0.501      0.702      0.774      0.764       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300       1.5G      1.449      1.513      1.175      1.029          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.724      0.807      0.806      0.517      0.702      0.785      0.777      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      1.49G      1.391      1.684      1.243      1.011          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.716      0.853      0.815       0.55      0.708      0.844      0.802       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300       1.5G      1.255      1.278       1.02     0.9507          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.752      0.858       0.84      0.573      0.748      0.853      0.831      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      1.49G      1.244      1.371      1.037     0.9538          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.776      0.803      0.835      0.562      0.772      0.799      0.825      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      1.49G      1.407      1.382      1.445      1.017          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.723      0.817      0.823      0.556      0.717      0.809      0.803      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      1.49G      1.289      1.402      1.103      0.956          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.807      0.778      0.831      0.538      0.797      0.757      0.793      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      1.49G      1.214      1.319      0.963     0.9521         14   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.84      0.793      0.862      0.572      0.845      0.761      0.827      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      1.49G      1.253      1.507     0.9421     0.9417          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.848      0.822      0.878      0.597      0.826      0.799      0.845      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      1.51G      1.165      1.355      1.103     0.9405          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.832      0.814      0.872      0.601      0.827      0.803      0.853      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      1.49G       1.26      1.272     0.9779     0.9737          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.864      0.803      0.868      0.583      0.844      0.782      0.846      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      1.47G      1.246      1.268     0.9927     0.9807          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.864      0.785      0.871      0.575      0.839      0.756      0.822      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      1.49G      1.202      1.378     0.9305     0.9475          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.865      0.785      0.869      0.574      0.824      0.735      0.798      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      1.49G      1.261      1.331      1.011     0.9915          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.85      0.776      0.867       0.58      0.808      0.729      0.804      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      1.49G      1.252      1.296      1.068     0.9785          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.806       0.74      0.862      0.586      0.781       0.71      0.814      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      1.49G      1.241      1.348      1.031     0.9597         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.792       0.84      0.879      0.615      0.758      0.807       0.83      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      1.49G      1.241      1.327      1.103     0.9479          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.826      0.826      0.889      0.626      0.795      0.796      0.844      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      1.49G      1.188      1.336      1.012     0.9217          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.791      0.847      0.886      0.628      0.755      0.809      0.839       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      1.49G      1.181      1.327     0.9064     0.9613         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.843      0.794      0.876      0.623      0.824      0.751      0.834      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      1.49G      1.142      1.178      0.914     0.9456          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.862       0.84      0.883      0.607      0.845      0.823      0.857      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      1.49G      1.161      1.211     0.9453     0.9763          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.572      0.706      0.661      0.436      0.567      0.674      0.634      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300       1.5G      1.129      1.228     0.8805     0.9573         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.245      0.471      0.283      0.189       0.24      0.463      0.274       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      1.49G      1.134      1.303     0.8884     0.9405          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.185      0.537      0.207      0.137      0.168      0.494      0.179     0.0807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      1.49G      1.215      1.301      1.101     0.9648         17   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.938      0.738      0.876      0.603      0.889      0.684      0.796      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      1.49G      1.156       1.14     0.8913      0.968          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.901      0.844      0.912      0.629      0.841      0.784      0.828      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      1.49G      1.171      1.135     0.8589     0.9185          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.906      0.844      0.915      0.638      0.862      0.801       0.86      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      1.48G      1.183      1.241     0.8469     0.8976          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.895      0.828      0.905      0.651      0.873      0.807      0.874      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      1.49G      1.145      1.353     0.8398     0.9338          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.882      0.859      0.913       0.65      0.882      0.859      0.898      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      1.49G       1.13      1.086     0.8995     0.8658          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.879      0.901      0.923      0.641      0.858       0.88      0.896      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      1.49G      1.101      1.073     0.8369     0.9305          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.878       0.91      0.923      0.629      0.843      0.872      0.884      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      1.49G      1.182      1.348      0.844     0.9388          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.883      0.851      0.912      0.582      0.857      0.786      0.853      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/300      1.49G      1.346      1.235     0.8287     0.9191          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.901      0.851      0.927      0.603      0.864      0.798      0.872      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/300      1.49G      1.178      1.281     0.8691     0.9185          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157        0.9      0.898      0.932      0.627      0.859      0.851      0.869      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/300      1.49G      1.128      1.268     0.8381     0.9277          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.905      0.919      0.927      0.639      0.881      0.894      0.892      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/300      1.49G      1.177       1.31     0.8812      0.978          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.934      0.896       0.93      0.657      0.908      0.872      0.895      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/300      1.49G      1.189      1.114     0.8737      1.015          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.925      0.848      0.914      0.651      0.906      0.825      0.866      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/300      1.49G      1.056      1.098     0.7487     0.9019          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.902      0.836      0.897      0.624      0.857      0.794      0.839      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/300      1.49G      1.179      1.103     0.8476     0.9483          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.878      0.839      0.893      0.585      0.829      0.787      0.817      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/300      1.47G      1.242      1.165     0.7897     0.9428          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.835      0.861      0.887      0.595      0.789      0.807      0.816      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/300      1.46G      1.206      1.233     0.8284     0.9227         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.855      0.865      0.906      0.648      0.828      0.844      0.869      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/300      1.49G      1.139      1.112     0.8271     0.9846          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.891      0.866      0.909      0.648      0.869      0.847      0.872      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/300       1.5G      1.245       1.19     0.8996      1.021          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.92      0.881      0.912      0.652      0.909      0.872      0.893      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/300      1.49G      1.297      1.353     0.8032     0.9952          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.895      0.873      0.914      0.677      0.878      0.848       0.88      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/300      1.49G       1.09      1.237     0.8407     0.9233          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.919      0.879      0.915      0.678      0.886      0.844      0.876      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/300      1.48G      1.139      1.255     0.9549     0.9582          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.889      0.882      0.916      0.657      0.855      0.808      0.839      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/300      1.49G      1.201      1.175     0.8441     0.9176          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.923      0.876       0.92       0.64      0.874      0.841      0.853      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/300       1.5G      1.109      1.249     0.8026      0.945          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.905      0.889      0.929      0.653      0.879      0.864      0.873      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/300      1.48G      1.065      1.118     0.8052     0.8718          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.871      0.879      0.927      0.653      0.853      0.862      0.888      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/300      1.49G      1.195       1.34     0.8082     0.9417          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.888      0.824      0.915      0.644      0.836      0.805      0.876      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/300      1.49G      1.104      1.077     0.8284      0.918          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.849      0.841      0.904      0.632      0.812      0.807       0.86      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/300      1.47G      1.048      1.156     0.7673     0.9515          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.834      0.895      0.912      0.644      0.781      0.835      0.849      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/300      1.48G      1.207      1.111     0.9705      1.028          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.827      0.875       0.91      0.636      0.791      0.792      0.829      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/300      1.49G      1.207      1.183     0.8014     0.9502          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.835      0.885      0.903      0.636       0.83      0.806      0.839      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/300      1.49G      1.172      1.224     0.8921     0.9306          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.849      0.853      0.907      0.618      0.813      0.811      0.832      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/300      1.49G      1.131      1.109     0.7972     0.9415          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.922      0.901      0.922      0.651      0.868      0.844      0.849      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/300      1.49G      1.118      1.236      0.894     0.9222          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.941       0.89      0.931      0.662      0.891      0.822      0.854      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/300      1.49G       1.15      1.228     0.8622     0.9345          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.922      0.902      0.928      0.654       0.87      0.851      0.848      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/300      1.48G      1.018      1.038     0.7941     0.9088         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.923      0.914      0.935      0.677      0.879      0.872      0.865      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/300      1.49G       1.06      1.022     0.8169     0.9487          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.921      0.914      0.936      0.701      0.887       0.88       0.88      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/300      1.47G      1.021      1.131     0.7339     0.9273          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.956      0.877      0.939      0.704       0.92      0.844      0.888      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/300      1.49G      1.031      1.117      0.859     0.8887          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.958      0.876      0.939      0.707      0.921      0.843      0.895      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/300      1.48G       1.13      1.273     0.8001     0.9534          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.931      0.865      0.932      0.702      0.908       0.83       0.89      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/300      1.49G      1.118      1.142     0.7747     0.9613          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.927       0.85      0.924       0.67      0.873      0.796      0.854      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/300      1.49G      1.099      1.123     0.7812     0.9224          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.909      0.867       0.91      0.657      0.856      0.812      0.849      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/300       1.5G      1.002      1.204     0.7679      0.862         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.893      0.856      0.898      0.669      0.845      0.804      0.841      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/300      1.49G      1.001      1.134     0.7154     0.9203          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.898      0.842      0.904      0.681      0.867      0.822      0.873      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/300      1.47G      1.019      1.147     0.7539     0.8962          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.891      0.859      0.911      0.688      0.863      0.848       0.89      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/300      1.49G      1.065      1.164     0.8644     0.8778          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.925      0.885      0.928      0.685      0.904      0.869      0.915      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/300      1.48G      1.109      1.111     0.9182      0.923         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.961      0.875      0.936      0.693      0.942      0.859      0.922      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/300      1.49G      1.169      1.135     0.8808     0.9318         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.931       0.92      0.941        0.7      0.905      0.895      0.917      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/300      1.51G      1.092      1.138     0.8338     0.9181         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.965      0.878      0.938        0.7      0.942       0.85      0.906      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/300      1.49G      1.057      1.154     0.8963     0.9024          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.95      0.909      0.942      0.697      0.903      0.864      0.893      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/300      1.49G       1.06      1.116     0.7504     0.9204          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.949      0.914      0.946      0.704      0.898      0.863      0.896      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/300      1.49G      1.044      1.062     0.7295     0.8812         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.93      0.918      0.948      0.699      0.877      0.863      0.897      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/300      1.49G      1.004      1.157     0.7124     0.8855          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.935       0.92      0.952       0.71      0.893      0.878      0.913      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/300      1.49G      1.078      1.095     0.7288     0.8711          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.931      0.919      0.951      0.719      0.901       0.89      0.923      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/300      1.49G     0.9833      1.037     0.7316      0.914          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.925      0.935      0.949      0.719      0.896      0.905      0.916      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/300      1.48G     0.9107      1.026     0.7089     0.8657          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.936      0.908      0.947      0.731      0.918      0.889      0.923      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/300      1.49G      1.063      1.204     0.9008     0.8892          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.934      0.928      0.948      0.734      0.905      0.899      0.913       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/300      1.49G       1.05      1.174     0.6994      0.935          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.933       0.93      0.953      0.731      0.904      0.901      0.927      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/300      1.49G     0.9413      1.097     0.7201     0.8866          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.933      0.932      0.956      0.733      0.901      0.897      0.931      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/300      1.49G     0.9498      1.076     0.6745       0.89          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.913      0.913      0.956      0.731       0.88      0.876      0.912      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/300      1.48G     0.9791      1.224     0.7417     0.8964          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.937      0.928      0.959      0.741      0.907        0.9      0.924      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/300       1.5G      1.005      1.168     0.6847     0.8762          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.931      0.929      0.959      0.742      0.908        0.9      0.923      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/300       1.5G      1.001      1.007      0.729     0.9292          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.913      0.939      0.955      0.731      0.902      0.896      0.924      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/300      1.49G     0.9122      1.012     0.6848     0.8905          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.921       0.91      0.947      0.716      0.903      0.887      0.918      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/300      1.49G      1.035      1.113      0.656     0.9286          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.946      0.913      0.953      0.735      0.917      0.883      0.918      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/300      1.49G     0.9724      1.116     0.7116     0.8911          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.96      0.913      0.955      0.739      0.919      0.867      0.909      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/300      1.49G      1.009       1.18     0.7583     0.9807          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.923      0.957      0.751       0.92      0.871      0.897       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/300      1.46G     0.9599      1.065     0.7346     0.9065          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.932      0.956       0.75      0.918      0.872      0.894      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    151/300      1.49G     0.9246      1.101     0.7254      0.896          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.951      0.931      0.955      0.751       0.91      0.877        0.9      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    152/300      1.49G     0.9305      1.066     0.6515     0.8628          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.936      0.926      0.956      0.737       0.89      0.879      0.907      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    153/300      1.49G     0.9505      1.035     0.7016     0.9327          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.941      0.929      0.959      0.717      0.894      0.882      0.912      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    154/300      1.49G     0.9732     0.9504     0.6821     0.9161          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.926      0.934      0.955       0.71      0.867      0.874      0.896      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    155/300      1.48G     0.9143     0.9608     0.7569     0.8648          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.898      0.944      0.961      0.727      0.855      0.898      0.918      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    156/300      1.49G     0.9393      1.124     0.6672     0.8884          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.95      0.909      0.961      0.738      0.905      0.859      0.918      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    157/300       1.5G     0.8875      1.004     0.6769     0.8861          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.938      0.913      0.959      0.743      0.904      0.874      0.924      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    158/300      1.48G      0.883     0.9573     0.6681     0.8641          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.919      0.905      0.951       0.74      0.917      0.826      0.893      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    159/300      1.49G     0.9873       1.17     0.7121     0.9304         17   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.905      0.906      0.951      0.735      0.855      0.854      0.891      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    160/300      1.48G     0.8947      1.051     0.7423     0.9058          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.944      0.905      0.952      0.739      0.895      0.855        0.9      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    161/300      1.48G     0.9325     0.8823     0.6707     0.9644          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.942      0.913      0.957      0.751      0.886      0.859      0.896      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    162/300      1.49G     0.9334     0.9342     0.6684     0.8743         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.928       0.92      0.956      0.733      0.864      0.854      0.886      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    163/300      1.49G      1.035      1.018     0.6387     0.8961          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.896      0.937       0.96      0.746      0.895      0.828      0.899      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    164/300      1.49G     0.8802      1.058     0.6321     0.8863          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.877      0.926      0.961      0.758      0.937      0.824      0.912      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    165/300       1.5G     0.9298      1.208     0.6281     0.8721          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157        0.9      0.898       0.96      0.756      0.924      0.823      0.913      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    166/300      1.47G     0.9962      1.053     0.6809     0.8855         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.874      0.934      0.958      0.758       0.95      0.831      0.918      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    167/300      1.48G     0.9092     0.9949     0.6958     0.8875          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.899      0.938      0.957      0.757       0.95      0.823      0.918       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    168/300      1.49G     0.9099       1.05     0.6403     0.8719          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.907      0.917      0.959       0.75       0.91       0.85      0.916      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    169/300      1.48G     0.9127      1.045     0.5978     0.8964         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.912      0.921      0.958      0.747      0.899      0.855      0.911      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    170/300       1.5G      0.949     0.9972     0.6137     0.9193          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.93      0.909       0.96      0.742      0.908      0.888      0.926      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    171/300      1.48G     0.9302     0.9581     0.6539     0.8596          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.946      0.913      0.961      0.747      0.906      0.875      0.915      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    172/300      1.49G     0.8539      1.128     0.6111     0.8776          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.948      0.909      0.962      0.749      0.904      0.867      0.907       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    173/300      1.48G      0.835     0.8272     0.5436     0.8004          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.968      0.889      0.964      0.748      0.921      0.842      0.904      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    174/300      1.48G     0.9709     0.9883     0.6278     0.8534          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.931      0.921      0.966      0.745      0.876      0.888      0.904      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    175/300      1.47G     0.8949      1.009     0.6323     0.8628          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.923      0.936      0.968      0.747      0.925      0.856      0.913      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    176/300      1.49G       0.98      1.213     0.7237     0.8912          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.911      0.946      0.967      0.759      0.924      0.858      0.919      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    177/300      1.49G     0.8697     0.9218     0.6084     0.8603          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.962        0.9      0.966      0.764      0.915      0.854      0.914      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    178/300      1.48G     0.8642     0.9302     0.6519       0.88          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.952      0.905      0.968      0.759      0.909      0.863      0.913      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    179/300      1.49G     0.9214     0.9982     0.6534     0.8892          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.948      0.917      0.966       0.75      0.906      0.875      0.904      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/300      1.49G     0.9269      1.045     0.6787     0.8579          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.972      0.908       0.97      0.754      0.888      0.871      0.898      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/300      1.48G     0.8669      0.854      0.707     0.8313          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.967      0.917       0.97      0.775      0.912      0.867      0.908      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/300      1.49G     0.8843     0.9275     0.6726     0.8841          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.948      0.943       0.97      0.782       0.89      0.888        0.9       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/300      1.49G     0.8526      0.952     0.6372     0.8649          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.961      0.922      0.968      0.779      0.904      0.867      0.898      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/300      1.49G     0.9302      1.024     0.6559     0.8809          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.961      0.942      0.968      0.775      0.895      0.873      0.887      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/300       1.5G      0.954       1.04     0.6534     0.8755          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.964      0.941      0.968       0.77      0.897      0.872      0.884      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/300       1.5G     0.8863     0.8878     0.5833     0.8622          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.963      0.941      0.967      0.762      0.899       0.87      0.883      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    187/300       1.5G     0.8853      1.106     0.6221      0.836          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.941       0.93      0.965      0.756      0.899      0.884       0.88      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    188/300      1.49G     0.8397     0.8931     0.6343      0.797          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.957      0.939      0.968       0.76      0.896       0.87      0.874      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    189/300      1.48G     0.8848     0.9866     0.6219     0.8483          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.955       0.94      0.971       0.77      0.886      0.854      0.857      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    190/300      1.49G      0.854      0.966     0.6257     0.8766         12   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.958      0.951      0.974      0.783      0.931      0.863      0.884      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    191/300      1.49G     0.8882     0.9897     0.6238     0.8568          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.965      0.952      0.976      0.778      0.948      0.871      0.901       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    192/300      1.49G     0.8869      1.036     0.6293     0.8845          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.962      0.957      0.976      0.782      0.909      0.887      0.906      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    193/300      1.49G      0.848     0.9351     0.6887     0.8379          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.968      0.946      0.977      0.781      0.925      0.899      0.918      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    194/300      1.49G     0.8816     0.9019     0.6128     0.8771          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.956      0.955      0.977      0.775      0.916      0.896      0.918      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    195/300      1.48G     0.8939     0.9231     0.6041     0.8685          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978       0.94      0.976      0.775      0.934      0.898      0.926      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    196/300      1.49G     0.9199     0.8946     0.6161     0.8781          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.952      0.942      0.969       0.78      0.915      0.906      0.931      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    197/300      1.49G     0.8676      1.143     0.6092     0.8857          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.952       0.94      0.967      0.782       0.92       0.91      0.929      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    198/300      1.49G     0.7998     0.9949     0.6144     0.8381          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.965      0.925      0.967      0.783      0.931      0.892      0.929      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    199/300      1.49G     0.8402      1.002      0.651     0.8558          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.964      0.917      0.965      0.795      0.917      0.898      0.921      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    200/300      1.49G     0.8534     0.8948     0.6563     0.8532          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.932       0.97      0.801      0.934      0.895      0.931      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    201/300      1.49G      0.876     0.9092     0.5711      0.865          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.971      0.947      0.971      0.798      0.932       0.91      0.928       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    202/300       1.5G     0.8491      0.944      0.563     0.8806          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.971       0.95       0.97      0.801      0.928      0.908      0.929      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    203/300      1.49G     0.8229     0.9167     0.5761     0.7861          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.954      0.972      0.794      0.927      0.908       0.92      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    204/300      1.49G     0.9148     0.9831     0.6626     0.8595          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.949      0.973      0.791      0.926      0.903      0.921      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    205/300      1.49G      0.868     0.8511     0.6249     0.8813          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.946      0.975      0.796      0.939      0.905       0.93      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    206/300      1.48G     0.8607      1.061     0.6202     0.8841          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.985      0.946      0.976      0.802      0.941      0.905      0.934      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    207/300      1.49G      0.837     0.9798     0.5914     0.8844          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.981      0.943      0.978      0.804      0.942      0.905      0.944      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    208/300       1.5G     0.9525       1.06     0.6758     0.8729          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.99      0.943      0.978      0.807       0.95      0.905      0.941      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    209/300      1.49G      0.807     0.8884     0.5958     0.8629          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.986      0.938      0.978       0.81      0.946        0.9      0.941      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    210/300      1.49G     0.9239     0.9068     0.5909     0.9054          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.987      0.938      0.978      0.812       0.95      0.898      0.934      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    211/300       1.5G      0.844     0.9622     0.5593     0.8439          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.984      0.933      0.978      0.808      0.944      0.896      0.928      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    212/300      1.49G     0.8738       1.01     0.6497     0.8499          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.946      0.978      0.802      0.945      0.896      0.922      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    213/300      1.48G     0.8639     0.8613     0.5605     0.8688          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.946      0.977      0.782      0.937      0.896      0.914      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    214/300       1.5G     0.8184     0.8775     0.5492     0.8512          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.946      0.977      0.804      0.938      0.896      0.914      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    215/300      1.48G     0.8992     0.8298     0.5888     0.8755          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.946      0.977      0.809      0.939      0.896      0.919      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    216/300      1.49G     0.8785     0.8919     0.5454     0.8491          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.966      0.956      0.977      0.808       0.92       0.91      0.939      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    217/300      1.47G     0.8312     0.8398      0.628     0.8678          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.969      0.957      0.978      0.809      0.923      0.911       0.94      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    218/300      1.49G     0.7938     0.8749     0.5958     0.8202          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.967      0.959      0.979       0.81      0.921      0.912       0.94      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    219/300      1.49G     0.7909      1.057     0.5158     0.8386          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.981      0.948      0.981      0.801      0.933      0.901      0.941      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    220/300      1.49G     0.7976     0.7629     0.5303     0.8679          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.98      0.948      0.981      0.809      0.946      0.914      0.951      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    221/300      1.49G     0.8487     0.9295     0.5176     0.8691          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.98      0.947       0.98      0.818      0.941      0.909       0.94      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    222/300      1.47G     0.7421     0.8512     0.5452     0.8334         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.98      0.947      0.979      0.814      0.945      0.913      0.944      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    223/300      1.49G     0.7823     0.8307     0.4996     0.8616          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.98      0.948      0.979      0.813      0.932      0.902      0.925      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    224/300      1.49G     0.8017     0.9005     0.6232     0.8584         18   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.979       0.95      0.978      0.804      0.931      0.904      0.925      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    225/300      1.49G     0.8078     0.8995     0.5191     0.8415         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.979       0.95      0.979      0.803      0.927        0.9      0.917      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    226/300      1.49G     0.8539     0.8972     0.5258     0.8441          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.947      0.978      0.795      0.912      0.885      0.901      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    227/300      1.49G     0.8395      1.012     0.5402     0.8375          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.968       0.95      0.977      0.795      0.902      0.888      0.895      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    228/300      1.49G     0.8421      1.001     0.5638     0.8417          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.976      0.944      0.978      0.809      0.906      0.878      0.893      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    229/300      1.48G     0.7751     0.7628     0.5101     0.7852          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982      0.938      0.979      0.821      0.929      0.888      0.904      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    230/300       1.5G     0.8024     0.9705     0.5969     0.8414          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.986      0.938      0.979      0.819      0.925      0.882      0.895      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    231/300      1.49G     0.7719     0.9083     0.5255      0.859          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.985      0.938      0.978      0.816      0.925      0.879       0.89      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    232/300      1.49G     0.7697     0.8518      0.518     0.8461         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.987      0.938      0.978      0.814      0.938      0.892      0.906      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    233/300      1.48G     0.8737     0.8197     0.5114     0.8672          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.984      0.938      0.978      0.813       0.93      0.887      0.901      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    234/300      1.49G     0.8051     0.9249     0.5245      0.859          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978       0.94      0.978      0.804      0.937      0.895       0.91      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    235/300      1.49G     0.8125     0.9679     0.5152     0.8528          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.946      0.977      0.811      0.919      0.877       0.89      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    236/300      1.48G     0.8271     0.8395     0.5228     0.8227          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.976       0.95      0.977      0.818      0.914      0.874      0.888      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    237/300      1.49G     0.8065     0.9231     0.4759     0.8452          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.946      0.976      0.823      0.909      0.868      0.885      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    238/300      1.49G     0.8126     0.8555     0.5259      0.861          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.979       0.94      0.977      0.828      0.914      0.875      0.891      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    239/300      1.49G     0.7484     0.8222     0.4899      0.856          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.949      0.978      0.832      0.925      0.883        0.9      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    240/300      1.49G     0.7272     0.7837     0.5035     0.8412          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982      0.938      0.979      0.843      0.929      0.887      0.907      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    241/300      1.49G     0.7941     0.8533     0.5111      0.853         13   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.969      0.959      0.979      0.839      0.946      0.904      0.921       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    242/300      1.49G     0.7697     0.8873     0.5131     0.8151          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.972      0.959       0.98      0.836      0.945      0.899       0.92      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    243/300       1.5G     0.7271     0.7544     0.4903     0.8373          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.97      0.946      0.981      0.828      0.932      0.889      0.914      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    244/300      1.49G     0.8031     0.9473     0.5038     0.8406          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.953      0.982      0.829      0.937      0.893      0.923      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    245/300      1.49G     0.7709     0.9339     0.5544     0.8437          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.952      0.982      0.826      0.941      0.892      0.924      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    246/300      1.49G     0.7491     0.8897     0.5002     0.8517          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.949      0.982      0.822      0.937      0.887       0.92      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    247/300      1.47G     0.7651     0.9527     0.5123     0.8769         17   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.969      0.946      0.977      0.822      0.938      0.887      0.921      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    248/300      1.49G     0.7539       1.01     0.4944      0.834          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.956      0.977      0.825      0.929      0.884      0.916      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    249/300      1.49G     0.7496     0.8542     0.4863     0.8477          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.979      0.969      0.983      0.836      0.934      0.897      0.916       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    250/300      1.49G     0.7545     0.9107      0.487     0.8517          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.969      0.983      0.836      0.936      0.915      0.925      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    251/300      1.49G     0.7696     0.8629     0.5091     0.8435          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978       0.95      0.981      0.838      0.935      0.908      0.925      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    252/300      1.48G     0.7307     0.9887     0.5291     0.8439          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.972      0.946      0.979      0.839      0.935      0.905      0.931      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    253/300      1.48G     0.7537     0.7784     0.6191     0.8977          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.951      0.981      0.832      0.926      0.897      0.913      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    254/300      1.47G     0.7077     0.8771     0.4991     0.8239          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.952      0.981      0.831      0.925      0.899      0.914      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    255/300      1.47G     0.7321     0.7439     0.4894     0.8315          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.953      0.981      0.824      0.919      0.877      0.899      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    256/300      1.49G     0.7605     0.8865     0.4802     0.8499         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.953      0.981      0.828      0.928      0.886      0.918      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    257/300      1.49G     0.6798     0.8559     0.5045     0.8574          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.953      0.981      0.842      0.928      0.885       0.92      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    258/300      1.49G     0.7255     0.8334     0.5009     0.8386          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982      0.965      0.982      0.844      0.922      0.906      0.923      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    259/300       1.5G     0.7048     0.8144     0.5074     0.8512          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982       0.97      0.983      0.851      0.911      0.898      0.902      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    260/300      1.49G     0.7345      0.968     0.4604     0.8312          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982      0.969      0.983      0.854      0.917      0.901      0.902      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    261/300      1.49G     0.7351     0.8267     0.4661     0.8192          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.982      0.969      0.983      0.851      0.915      0.901      0.903      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    262/300      1.47G     0.7046     0.8041     0.4781     0.8465          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.957      0.983      0.842      0.912      0.892      0.908      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    263/300      1.49G     0.6832     0.8067     0.4663     0.8394          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.956      0.983      0.843      0.906      0.886      0.897      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    264/300      1.47G     0.7118     0.9019     0.4719      0.849          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157       0.98      0.947      0.983      0.841       0.91       0.88      0.899      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    265/300      1.49G     0.6951     0.8658     0.4432     0.8218          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.979      0.947      0.983      0.836      0.905      0.876      0.896      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    266/300       1.5G     0.8414     0.9192     0.5046     0.8562         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975       0.95      0.982      0.835      0.907      0.882      0.901      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    267/300      1.49G     0.7235     0.8741     0.5104      0.859          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.975      0.954      0.982      0.848      0.933      0.907      0.926      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    268/300      1.49G     0.6741     0.7306     0.4809     0.8393          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.976      0.955      0.982      0.848      0.925      0.893      0.917      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    269/300      1.48G      0.688     0.8541     0.4798     0.8229          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.955      0.982      0.852      0.922      0.896       0.92      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    270/300      1.47G     0.7108     0.8421     0.4773     0.8383          7   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.955      0.982      0.852      0.917      0.896      0.921      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    271/300      1.49G     0.7696     0.7931     0.4851      0.844         11   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.955      0.983      0.856      0.917      0.896      0.921      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    272/300      1.49G     0.7299     0.8426     0.5102     0.8401          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.955      0.983      0.854      0.914      0.896      0.921      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    273/300      1.49G     0.6814     0.7809     0.5164     0.8491         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.957      0.983      0.854      0.931      0.878      0.917      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    274/300       1.5G     0.6729      0.772     0.4512     0.8443          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.973      0.959      0.983       0.85      0.931      0.879      0.916      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    275/300       1.5G     0.6361     0.8252     0.5515     0.7986          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.974      0.959      0.983      0.856      0.924      0.874      0.911      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    276/300      1.49G      0.661     0.9419     0.4505     0.8312          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.978      0.957      0.983      0.854      0.919      0.883      0.913       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    277/300      1.49G     0.6727     0.7959     0.4486     0.8193          4   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.956      0.983      0.854      0.924      0.887      0.926      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    278/300      1.49G     0.6236      0.676     0.4476     0.8132          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.977      0.956      0.983      0.856      0.926      0.885      0.923      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    279/300      1.48G     0.6793     0.8061     0.4528     0.8463          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.963      0.971      0.984      0.857      0.927      0.884      0.924      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    280/300      1.47G     0.6473     0.7674     0.4381      0.843          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.963      0.983      0.984      0.861      0.928      0.885      0.923      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    281/300      1.48G     0.6522     0.8292      0.465     0.8326          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.959      0.979      0.984      0.866      0.928      0.885      0.925      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    282/300       1.5G     0.7147     0.8663     0.4639     0.8486          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.962      0.982      0.984      0.869      0.929      0.885      0.925      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    283/300      1.49G      0.669     0.7529     0.5106     0.8249          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.959      0.981      0.984      0.864      0.929      0.885      0.921      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    284/300      1.49G     0.7717     0.8809     0.5266     0.8338          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.959      0.978      0.984      0.857       0.93      0.885      0.921      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    285/300      1.49G     0.6884     0.7755     0.4814     0.8355          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.987      0.948      0.985      0.861       0.93      0.894      0.921      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    286/300      1.49G     0.6657     0.7181     0.4503     0.8187          9   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.987       0.95      0.985      0.864       0.93      0.896      0.926      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    287/300      1.46G     0.6844     0.7125     0.4368     0.8345          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.987       0.95      0.985      0.869       0.93      0.897      0.926      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    288/300      1.49G     0.6869     0.8074     0.4384      0.824          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.969      0.955      0.984      0.868      0.934      0.885      0.932      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    289/300      1.49G     0.6454     0.7818     0.4752     0.8199         10   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.955      0.979      0.984      0.864      0.902      0.919      0.928      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    290/300       1.5G     0.6792     0.7229     0.4654     0.8205          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.954      0.979      0.984      0.867      0.913      0.899      0.919      0.566\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    291/300      1.49G     0.6783     0.8128     0.4825     0.8289          6   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.964      0.962      0.983      0.865      0.959      0.904      0.951      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    292/300      1.49G     0.6577     0.6646     0.4662     0.8682          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.988      0.934      0.983      0.858      0.957      0.905      0.946       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    293/300      1.49G     0.6923     0.8873     0.4768     0.8097          5   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.938      0.982      0.849      0.958      0.898      0.941      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    294/300      1.48G     0.6568     0.7465     0.4213     0.8504          8   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.937      0.982      0.848      0.962      0.902      0.948      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    295/300      1.49G     0.6285     0.7329     0.4843     0.8111          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.938      0.982      0.849      0.959      0.902      0.947      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    296/300      1.47G     0.7033     0.7795     0.4649     0.8045          0   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.939      0.982      0.851      0.955      0.897      0.939      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    297/300       1.5G     0.6382     0.6858     0.4647     0.8579          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.983      0.939      0.982      0.852      0.955      0.897      0.939      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    298/300      1.48G     0.6896     0.8117      0.471     0.8486          3   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.984      0.934      0.982      0.847      0.958      0.897      0.939      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    299/300      1.49G     0.6785     0.7574     0.4616     0.8404          2   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.984      0.935      0.983      0.854      0.955      0.905      0.944      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    300/300      1.49G     0.6322     0.7867     0.4629     0.9084          1   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.985      0.936      0.983      0.848      0.955      0.905      0.945       0.56\n",
      "\n",
      "300 epochs completed in 0.136 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 23.9MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 23.9MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.4 torch-2.4.0+cu121 CUDA:0 (NVIDIA RTX A4500, 20047MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11780374 parameters, 0 gradients, 42.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         70        157      0.964      0.962      0.983      0.863      0.959      0.904      0.951      0.574\n",
      "              kurohagi         70         41      0.975       0.95      0.974       0.88      0.973      0.894       0.94      0.635\n",
      "         rurisuzumedai         70        116      0.954      0.974      0.992      0.847      0.945      0.914      0.962      0.513\n",
      "Speed: 0.5ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "results = model.train(data=\"/home/nakahira/workspace/Nishida/fish/seavis1003/fish-1/data.yaml\", batch=4, epochs=300, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MScstfHhArr",
    "outputId": "70e28b87-1d0f-4c77-eaee-0621de1b34b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.yaml\t\t\t MaskP_curve.png      train_batch5222.jpg\n",
      "BoxF1_curve.png\t\t\t MaskPR_curve.png     val_batch0_labels.jpg\n",
      "BoxP_curve.png\t\t\t MaskR_curve.png      val_batch0_pred.jpg\n",
      "BoxPR_curve.png\t\t\t results.csv\t      val_batch1_labels.jpg\n",
      "BoxR_curve.png\t\t\t results.png\t      val_batch1_pred.jpg\n",
      "confusion_matrix_normalized.png  train_batch0.jpg     val_batch2_labels.jpg\n",
      "confusion_matrix.png\t\t train_batch1.jpg     val_batch2_pred.jpg\n",
      "labels_correlogram.jpg\t\t train_batch2.jpg     weights\n",
      "labels.jpg\t\t\t train_batch5220.jpg\n",
      "MaskF1_curve.png\t\t train_batch5221.jpg\n"
     ]
    }
   ],
   "source": [
    "#!ls {HOME}/runs/segment/train/\n",
    "!ls /home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "_J35i8Ofhjxa",
    "outputId": "d89a5193-1e58-4be9-bc6a-e3e5945202c1",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%cd {HOME}\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Image(filename=f'{HOME}/runs/segment/train8/confusion_matrix.png', width=600)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mImage\u001b[49m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/train/results.png\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "#%cd {HOME}\n",
    "#Image(filename=f'{HOME}/runs/segment/train8/confusion_matrix.png', width=600)\n",
    "Image(filename=f'/home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/train/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 20 18:03:29 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4500               Off |   00000000:01:00.0  On |                  Off |\n",
      "| 30%   36C    P8             20W /  200W |     471MiB /  20470MiB |      5%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1819      G   /usr/lib/xorg/Xorg                            106MiB |\n",
      "|    0   N/A  N/A      2010      G   /usr/bin/gnome-shell                           68MiB |\n",
      "|    0   N/A  N/A      2926      G   gnome-control-center                          107MiB |\n",
      "|    0   N/A  N/A      3480      G   ...irefox/4757/usr/lib/firefox/firefox        163MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.6ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.7ms\n",
      "Speed: 2.2ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 rurisuzumedais, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 7 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 11 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 7 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 3.6ms\n",
      "Speed: 1.9ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 2.0ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.2ms\n",
      "Speed: 1.5ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.3ms\n",
      "Speed: 1.3ms preprocess, 4.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.3ms\n",
      "Speed: 2.0ms preprocess, 4.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 7.2ms\n",
      "Speed: 3.0ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.4ms\n",
      "Speed: 1.2ms preprocess, 4.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.1ms\n",
      "Speed: 1.5ms preprocess, 4.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 6.6ms\n",
      "Speed: 2.4ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 7.2ms\n",
      "Speed: 2.1ms preprocess, 7.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.8ms preprocess, 3.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.2ms\n",
      "Speed: 1.6ms preprocess, 4.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 2.1ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 2.1ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.4ms\n",
      "Speed: 2.5ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.9ms preprocess, 3.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.8ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 2.1ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.9ms preprocess, 4.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 2.2ms preprocess, 3.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.9ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 2.7ms preprocess, 4.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 2.1ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.3ms\n",
      "Speed: 1.5ms preprocess, 4.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 6.5ms\n",
      "Speed: 2.1ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 5.3ms\n",
      "Speed: 2.1ms preprocess, 5.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.0ms\n",
      "Speed: 2.5ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 4.2ms\n",
      "Speed: 2.3ms preprocess, 4.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 4.2ms\n",
      "Speed: 1.3ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.9ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 4.4ms\n",
      "Speed: 1.8ms preprocess, 4.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 2.0ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.8ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 6.4ms\n",
      "Speed: 2.1ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.7ms\n",
      "Speed: 2.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 5 rurisuzumedais, 6.3ms\n",
      "Speed: 2.1ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 5 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.9ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.8ms\n",
      "Speed: 1.6ms preprocess, 3.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.9ms\n",
      "Speed: 1.9ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 4.9ms\n",
      "Speed: 1.6ms preprocess, 4.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.7ms\n",
      "Speed: 1.8ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 6.3ms\n",
      "Speed: 2.0ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 4.4ms\n",
      "Speed: 1.5ms preprocess, 4.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 2.0ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 2.0ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.1ms\n",
      "Speed: 1.5ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 4 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.8ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.7ms\n",
      "Speed: 2.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.7ms\n",
      "Speed: 1.8ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.9ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.8ms\n",
      "Speed: 2.1ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.5ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 4.0ms\n",
      "Speed: 1.9ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.8ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 6.2ms\n",
      "Speed: 2.1ms preprocess, 6.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.9ms\n",
      "Speed: 1.9ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.1ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.9ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 2.1ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 6.4ms\n",
      "Speed: 2.1ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.7ms\n",
      "Speed: 2.0ms preprocess, 4.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.8ms\n",
      "Speed: 2.0ms preprocess, 3.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 rurisuzumedais, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.3ms\n",
      "Speed: 2.8ms preprocess, 4.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 kurohagis, 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 kurohagi, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.7ms\n",
      "Speed: 1.9ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 4.1ms\n",
      "Speed: 2.3ms preprocess, 4.1ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 rurisuzumedai, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "#fish count(Video) \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model_file = '/home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/train/weights/best.pt'\n",
    "#model_file = '/home/nakahira/workspace/nakahira/real_coral_fish_train_yolov8/runs/detect/train3/weights/best.pt'\n",
    "\n",
    "model = YOLO(model_file)\n",
    "\n",
    "class_names = model.names\n",
    "\n",
    "#Add Color\n",
    "colors = [(255,0,0), (0,255,0),(0,0,255)]\n",
    "\n",
    "video_path = '/home/nakahira/workspace/nakahira/seavis/OnnaDataset/GH012962.MP4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "#file name number change!\n",
    "out = cv2.VideoWriter('/home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/predict/output_video8.mp4', fourcc, 30.0, (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "frame_fish_counts = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    \n",
    "    class_counts = {}\n",
    "\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            class_id = int(detection.cls.item())\n",
    "            x1,y1,x2,y2 = map(int, detection.xyxy[0])\n",
    "            confidence = detection.conf[0]         \n",
    "            label = class_names[class_id]\n",
    "            \n",
    "            if confidence > 0.3:\n",
    "                fish_count += 1\n",
    "                class_name = class_names[int(class_id)]\n",
    "                \n",
    "                if class_name not in class_counts:\n",
    "                    class_counts[class_name] = 0\n",
    "                    \n",
    "                class_counts[class_name] += 1\n",
    "                color = colors[int(class_id) % len(colors)]\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)),(int(x2), int(y2)), color, 2)\n",
    "                label = f'{class_names[int(class_id)]}:{confidence:.2f}'\n",
    "                cv2.putText(frame, label,(int(x1),int(y1) - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    y_offset = 30\n",
    "    for class_name, count in class_counts.items():\n",
    "        cv2.putText(frame, f'{class_name}:{count}', (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        y_offset += 30\n",
    "            \n",
    "    frame_fish_counts.append(class_counts)\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "np.save('frame_fish_counts.npy', frame_fish_counts)\n",
    "\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frame_counts = np.load('frame_fish_counts.npy', allow_pickle = True)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "#Add Color\n",
    "colors = ['b','g','r','c','m','y','k']\n",
    "\n",
    "all_class_names = set()\n",
    "for frame in frame_counts:\n",
    "    all_class_names.update(frame.keys())\n",
    "\n",
    "num_classes = len(all_class_names)\n",
    "fig, axes = plt.subplots(num_classes, 1, figsize = (10, 5 * num_classes))\n",
    "\n",
    "for i, (class_name, color) in enumerate (zip(all_class_names, colors)):\n",
    "    counts = [frame.get(class_name, 0) for frame in frame_counts]\n",
    "    axes[i].plot(counts, label = class_name, color = color)\n",
    "    axes[i].set_xlabel('Frame_Number')\n",
    "    axes[i].set_ylabel('Fish_Count')\n",
    "    axes[i].set_title(f'Fish Count per Frame:{class_name}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "\n",
    "#graph_file name number change!\n",
    "plt.savefig('/home/nakahira/workspace/Nishida/fish/seavis1003/runs/segment/plot_graph/output_graph1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ODk1VTlevxn",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpyuwrNlXc1P",
    "outputId": "be5030a3-7431-4c5d-9e6b-9a3b90793f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nakahira/workspace/seavis2024/seavis0827\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA RTX A4500, 20047MiB)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11779987 parameters, 0 gradients, 42.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nakahira/workspace/seavis2024/seavis0827/sanngo2-1/valid/lab\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         63        245      0.908      0.759      0.877      0.657      0.889      0.759      0.866      0.534\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=segment mode=val model={HOME}/runs/segment/train2/weights/best.pt data={dataset.location}/data.yaml"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
